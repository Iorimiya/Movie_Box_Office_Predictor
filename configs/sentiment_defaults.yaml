# Default configuration parameters for the sentiment analysis model training pipeline.
# These values are used when a training run is initiated without specific overrides.
# The 'model_id' must be provided by the user for each run and is not included here.

# --- Data Source & Processing ---
# The name of the source CSV file located in 'inputs/sentiment_analysis_resources/'.
dataset_file_name: "lexicon_sentiment_data.csv"

# The maximum number of unique words to keep in the vocabulary.
vocabulary_size: 5000

# The ratios for splitting data into training, validation, and test sets.
# Format: [train_parts, validation_parts, test_parts]
# e.g., [8, 1, 1] means 80% train, 10% validation, 10% test.
split_ratios: [8, 1, 1]

# The seed for the random number generator to ensure reproducible data splits.
# random_state: 42


# --- Model Architecture ---
# The dimensionality of the word embedding vectors.
embedding_dim: 64

# The number of units (neurons) in the LSTM layer.
lstm_units: 128


# --- Training Process ---
# The total number of epochs to train the model.
epochs: 100

# The number of samples per gradient update.
batch_size: 32

# Verbosity mode for Keras training output. 0 = silent, 1 = progress bar, 2 = one line per epoch.
verbose: 1

# The interval in epochs at which to save model checkpoints.
# Set to null or remove the line to disable periodic checkpointing and only save the final model.
checkpoint_interval: 20
