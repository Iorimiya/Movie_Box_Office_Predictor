| PredictionDataProcessor 中的方法/邏輯 | 對應到 MoviePredictionModel 中的方法/邏輯 | 說明 | 
| :--- | :--- | :--- |
| load_raw_data() | _load_training_data() | 職責：載入原始資料。兩者都從指定的 `dataset` 載入電影資料，並呼叫一個輔助函式將每部電影的資料轉換成 MoviePredictionInputData 的格式。 |
| _transform_single_movie_data() | __transform_single_movie_data() | 職責：轉換單一電影資料。這兩個方法的功能幾乎完全相同，都是將一個 MovieData 物件轉換為按週劃分的特徵列表。新版本的程式碼更簡潔。 | 
| process_for_training() | _prepare_data() | 職責：為訓練準備資料 (主流程)。這是最核心的對應。舊的 _prepare_data 是一個巨大的函式，完成了所有事情。新的 process_for_training 則是一個協調者，它呼叫多個更小、更專注的輔助方法來完成同樣的任務，流程更清晰。 | 
| _preprocess_to_numerical() | __preprocess_data() | 職責：將資料轉換為數值格式。兩者都將 MoviePredictionInputData 轉換為 [box_office, avg_sentiment, replies_count] 的數值列表。新版本在過濾無效資料方面更明確。 | 
| _create_sequences() | _prepare_data() 內部的序列生成迴圈 | 職責：建立時間序列樣本。舊程式碼中建立 x 和 y 的迴圈以及後續的 pad_sequences 呼叫，現在被提取到這個獨立的方法中。 | 
| _split_and_scale_data() | _prepare_data() 內部的資料分割與縮放邏輯 | 職責：分割與縮放資料。這是一個重要的重構。它將資料分割（train/val/test）和特徵縮放的邏輯封裝在一起。特別是，它遵循了機器學習的最佳實踐：MinMaxScaler 僅在訓練集 (y_train) 上進行 fit，然後用同一個 scaler 去 transform 驗證集和測試集。 | 
| _scale_feature_in_sequences() | _prepare_data() 內部對 x_train, x_val, x_test 的縮放迴圈 | 職責：縮放輸入序列中的特徵。舊程式碼中有三個獨立的迴圈來縮放 x 資料集中的票房特徵。這個邏輯現在被抽象成一個可重用的輔助方法。 | 
| process_for_prediction() | predict() 方法內部的資料準備部分 | 職責：為單次預測準備輸入資料。舊的 predict 方法中，資料預處理的程式碼和模型預測呼叫混在一起。新類別將資料準備的邏輯完全分離到此方法中，使得 predict 的流程更純粹。 | 
| save_artifacts() / load_artifacts() | __save_scaler(), __save_training_setting(), __load_training_setting() | 職責：儲存/載入附屬產物。舊程式碼使用 joblib 儲存 scaler，用 yaml 儲存設定。新方法將 scaler 和相關設定 (training_week_limit, training_data_len) 一起打包到一個 pickle 檔案中，管理更為統一和簡單。 |

ReviewSentimentAnalyseModel (分類模型) 的學術評估對於情感分析這類分類問題，學術評估的重點在於全面地衡量模型在各個類別上的預測能力，而不僅僅是看整體的準確率。應生成的比較值：

1.混淆矩陣 (Confusion Matrix):•是什麼: 一個表格，顯示了模型預測結果與真實標籤的對比。包含四個核心值：•True Positives (TP): 實際為正，預測也為正。•True Negatives (TN): 實際為負，預測也為負。•False Positives (FP): 實際為負，但錯誤地預測為正 (Type I Error)。•False Negatives (FN): 實際為正，但錯誤地預測為負 (Type II Error)。•為何重要: 它是計算後續所有指標的基礎，能最直觀地看出模型在哪一類上更容易犯錯。2.準確率 (Accuracy):•是什麼: (TP + TN) / (TP + TN + FP + FN)，即所有預測正確的樣本佔總樣本的比例。•為何重要: 最直觀的性能指標。但在資料不平衡時具有誤導性，因此學術上絕不會單獨使用它。

3.精確率 (Precision):•是什麼: TP / (TP + FP)，在所有被模型預測為「正面」的評論中，有多少是真的正面。•為何重要: 衡量模型的「查準率」。高 Precision 意味著模型預測為正的結果非常可信。

4.召回率 (Recall / Sensitivity):•是什麼: TP / (TP + FN)，在所有真實為「正面」的評論中，有多少被模型成功地找了出來。•為何重要: 衡量模型的「查全率」。高 Recall 意味著模型能有效地捕捉到所有正面的樣本，漏網之魚很少。

5.F1-Score:•是什麼: Precision 和 Recall 的調和平均數 (2 * (Precision * Recall) / (Precision + Recall))。•為何重要: 一個綜合 Precision 和 Recall 的指標，當兩者都高時，F1-Score 才會高。它比 Accuracy 在不平衡資料集上更具參考價值。

6.ROC 曲線與 AUC 值 (Receiver Operating Characteristic Curve & Area Under the Curve):•是什麼: ROC 曲線是一個圖表，橫軸是「假正率 (FPR)」，縱軸是「真正率 (TPR, 即 Recall)」。它展示了在所有可能的分類閾值下，模型的性能權衡。AUC 則是這條曲線下的面積。•為何重要: AUC 是一個介於 0.5 和 1 之間的值，它衡量了模型整體區分正負樣本的能力，且不受特定分類閾值（例如 0.5）的影響。AUC 越高，模型性能越好。這是比較不同分類模型性能的黃金標準。



MoviePredictionModel (迴歸模型) 的學術評估對於票房預測這類迴歸問題，學術評估的重點在於衡量預測值與真實值之間的誤差大小和模型的擬合優度。應生成的比較值：

1.均方誤差 (Mean Squared Error, MSE):•是什麼: 預測誤差的平方的平均值。•為何重要: 這是迴歸任務中最常用的損失函數和評估指標。它對較大的誤差給予較高的懲罰。缺點是其單位是原始單位的平方（例如「元平方」），不夠直觀。

2.均方根誤差 (Root Mean Squared Error, RMSE):•是什麼: MSE 的平方根。•為何重要: 這是學術上最受歡迎的迴歸指標之一。它的單位與目標變數的單位相同（例如「元」），因此非常直觀。它代表了模型預測的平均誤差幅度。

3.平均絕對誤差 (Mean Absolute Error, MAE):•是什麼: 預測誤差的絕對值的平均值。•為何重要: 單位也與目標變數相同。與 RMSE 相比，MAE 對異常值 (outliers) 不那麼敏感。同時報告 RMSE 和 MAE 可以幫助了解誤差分佈中是否存在較多的極端值。

4.決定係數 (R-squared, R²):•是什麼: 衡量模型解釋的變異數佔總變異數的比例。其值介於負無窮到 1 之間。•為何重要: 衡量模型的「擬合優度」。R² 為 1 表示完美擬合；R² 為 0 表示模型的表現和直接預測平均值一樣差；R² 為負則表示模型比平均值還要差。它提供了一個相對的性能度量，不受目標變數尺度的影響。

5.平均絕對百分比誤差 (Mean Absolute Percentage Error, MAPE):•是什麼: 預測誤差的絕對值佔真實值的百分比的平均值。•為何重要: 提供了一個直觀的、無單位的百分比誤差，非常適合向非技術人員報告或在不同尺度的數據集之間比較模型。需要注意，當真實值為 0 時，此指標無定義。







對於票房預測這種迴歸 (Regression) 問題，我們無法「直接」計算 F1-score。為什麼不能直接計算？F1-score 的計算基礎是混淆矩陣 (Confusion Matrix)，它需要明確的分類結果，如「True Positive」、「False Positive」等。但迴歸模型的輸出是一個連續的數值（例如，預測票房為 5,432,100 元），而不是一個離散的類別。你無法說一個預測值是「True Positive」，因為它沒有對應的「類別」。如何巧妙地應用 F1-Score？儘管不能直接應用，但我們可以將迴歸問題轉換為分類問題來進行評估。這正是舊版 box_office_prediction.py 中 calculate_f1_score_for_ranges 方法背後的思想，這是一個非常成熟和有洞察力的評估方法。轉換步驟如下：1.定義類別 (Define Classes): 我們將連續的票房數值劃分為幾個離散的區間 (Ranges) 或稱之為箱 (Bins)。例如：•Class 0: < 1,000,000 (小型電影)•Class 1: 1,000,000 到 10,000,000 (中型電影)•Class 2: 10,000,000 到 90,000,000 (熱門電影)•Class 3: >= 90,000,000 (超級賣座電影)

轉換問題 (Transform the Problem): 現在，模型的評估任務不再是「預測的數值有多接近？」，而是「模型預測的票房落在了哪個區間（類別）？」。這就變成了一個多分類 (Multi-class Classification) 問題。3.計算 F1-Score: 一旦我們有了「預測的類別」和「真實的類別」，我們就可以為這個多分類問題計算 F1-score。為什麼這個衍生指標在學術上很有價值？•提供業務洞察: 它能告訴我們模型在識別不同「量級」的電影方面的表現。例如，一個模型的 MSE 可能很低，但它可能總是將「超級賣座電影」錯誤地預測為「熱門電影」。F1-score for ranges 就能揭示這個問題。•多維度評估: 它為評估迴歸模型提供了一個全新的維度，補充了 RMSE、MAE 和 R² 等傳統指標的不足。•可比性: 只要不同模型使用相同的區間定義，它們的 F1-score for ranges 就是可以互相比較的。



# 結論

- 兩者需生成training loss, validation loss來解釋訓練過程的變化
- 需要test loss，但僅作為下列兩點的生成基礎
- 對訓練完的模型來說，sentiment需要f1-score、Accuracy等資料解釋成效
- 對訓練完的模型來說，prediction需要RMSE、R^2等資料解釋成效

- 學術上的需求除外，應在業務上需求為prediction建立range f1-score



| 功能面向 (Functional Aspect) | SentimentDataProcessor (情感分析) | PredictionDataProcessor (票房預測) | 說明與比較 (Explanation & Comparison) |
| :--- | :--- | :--- | :--- |
| 核心職責 | 將正/負面詞彙的 CSV 檔，轉換為模型可用的已編碼、已填充 (padded) 的文字序列。 | 將 MovieData 物件，轉換為模型可用的已縮放、已填充 (padded) 的時間序列。 | 兩者的最終目標都是產生 (x, y) 的數值陣列，但前處理的複雜度與類型完全不同。 | 
| 泛型與繼承 | BaseDataProcessor[DataFrame, ...] | BaseDataProcessor[list[MovieData], ...] | Sentiment 使用了通用的 pandas.DataFrame 作為原始資料輸入，而 Prediction 使用了專案自訂的 list[MovieData]。這反映了 Sentiment 的資料來源更為單純。 |
| 初始化 (__init__) | 初始化 self.tokenizer 和 self.max_sequence_length。 | 初始化 self.scaler、self.training_week_limit 和 self.training_data_len。 | 兩者都正確地初始化了各自需要儲存的「產物 (artifacts)」變數。 | 
| 產物管理 (save/load_artifacts) | 儲存/載入 tokenizer 和 max_sequence_length 到 tokenizer.pickle。 | 儲存/載入 scaler、training_week_limit 和 training_data_len 到 scaler_and_settings.pickle。 | 模式完全相同。兩者都將訓練過程中產生的、預測時也需要用到的「狀態」打包成一個檔案，這是非常好的設計。 | 
| 載入原始資料 (load_raw_data) | 從 CSV 載入資料到 pandas.DataFrame。 | 從 Dataset 物件載入資料，得到 list[MovieData]。 | 語意一致。兩者都只負責「載入」最原始的資料，而不做任何轉換，這符合您先前討論的設計原則。 |
| 處理訓練資料 (process_for_training) | 協調 _construct_and_segment_texts, _tokenize_and_pad_sequences, _split_data 的執行順序。 | 協調 _transform_raw_to_weekly_data, _preprocess_to_numerical, _create_sequences, _split_and_scale_data 的執行順序。 | 角色相同。兩者都是總指揮，負責調度內部的私有方法，完成從原始資料到最終 Processed...Data 的完整流程。 | 
| 處理預測資料 (process_for_prediction) | 輸入 str，進行斷詞、tokenize、padding。 | 輸入 MovieData，轉換為數值序列，進行 scaling 和 padding。 | 角色相同。兩者都只處理「單一輸入」，並使用 load_artifacts 載入的產物（tokenizer 或 scaler）來進行處理。 | 
| 資料轉換 (Transformation) | _construct_and_segment_texts：從詞彙建構出完整的句子。 | _transform_raw_to_weekly_data：將 MovieData 轉換為 list[WeekData]。<br>_preprocess_to_numerical：將 WeekData 轉換為數值特徵。 | Prediction 的轉換步驟更複雜，分為兩步。Sentiment 的轉換相對單純。 |
| 序列化 (Sequencing) | _tokenize_and_pad_sequences：使用 Tokenizer 將文字轉為數字序列，並進行 padding。 | _create_sequences：使用滑動窗口 (sliding window) 的方式，手動從時間序列中切出 (X, y) 對，並進行 padding。 | 目標相同，方法不同。兩者都是為了產生模型可用的、等長的數值序列。Sentiment 依賴 Keras 的標準工具，而 Prediction 則需要客製化的時間序列切片邏輯。 | 
| 資料分割 (Splitting) | _split_data：使用 sklearn.model_selection.train_test_split，並設定 random_state 和 stratify。 | _split_and_scale_data：使用簡單的陣列切片 (slicing) x[:train_end_idx]。 | 這是最關鍵的差異點。<br>• Sentiment 的作法更優越：使用 random_state 確保了每次分割的結果都可重現。使用 stratify=y_data 確保了訓練、驗證、測試集中的正負樣本比例一致，這對於分類問題至關重要。<br>• Prediction 的作法較為簡單：按順序分割。這種方法雖然簡單，但不具備隨機性，如果資料的順序有特定模式，可能會導致偏差。 |
| 資料縮放 (Scaling) | (無) | _split_and_scale_data 和 _scale_feature_in_sequences：使用 MinMaxScaler。 | 這是 Prediction 模型特有的步驟，因為它處理的是連續的數值特徵。Sentiment 的作法是正確的：只在 y_train 上 fit scaler，然後用這個 scaler 去 transform 其他所有資料，避免了資料洩漏。 |